{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "920f8085",
   "metadata": {},
   "source": [
    "# Ensemble Methods for Regression\n",
    "In this notebook, we will demonstrate how to use ensemble methods for regression using the **Random Forest Regressor** and **Gradient Boosting Regressor**. We will also explore combining these models using the **Voting Regressor** and **Stacking Regressor**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6beea3",
   "metadata": {},
   "source": [
    "### Step 1: Load and Preprocess the Dataset\n",
    "We'll load the **California Housing Prices** dataset and preprocess it for regression tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f05dbdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "      <th>medianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-114.31</td>\n",
       "      <td>34.19</td>\n",
       "      <td>15</td>\n",
       "      <td>5612</td>\n",
       "      <td>1283</td>\n",
       "      <td>1015</td>\n",
       "      <td>472</td>\n",
       "      <td>1.4936</td>\n",
       "      <td>66900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-114.47</td>\n",
       "      <td>34.40</td>\n",
       "      <td>19</td>\n",
       "      <td>7650</td>\n",
       "      <td>1901</td>\n",
       "      <td>1129</td>\n",
       "      <td>463</td>\n",
       "      <td>1.8200</td>\n",
       "      <td>80100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-114.56</td>\n",
       "      <td>33.69</td>\n",
       "      <td>17</td>\n",
       "      <td>720</td>\n",
       "      <td>174</td>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>1.6509</td>\n",
       "      <td>85700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-114.57</td>\n",
       "      <td>33.64</td>\n",
       "      <td>14</td>\n",
       "      <td>1501</td>\n",
       "      <td>337</td>\n",
       "      <td>515</td>\n",
       "      <td>226</td>\n",
       "      <td>3.1917</td>\n",
       "      <td>73400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-114.57</td>\n",
       "      <td>33.57</td>\n",
       "      <td>20</td>\n",
       "      <td>1454</td>\n",
       "      <td>326</td>\n",
       "      <td>624</td>\n",
       "      <td>262</td>\n",
       "      <td>1.9250</td>\n",
       "      <td>65500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housingMedianAge  totalRooms  totalBedrooms  \\\n",
       "0    -114.31     34.19                15        5612           1283   \n",
       "1    -114.47     34.40                19        7650           1901   \n",
       "2    -114.56     33.69                17         720            174   \n",
       "3    -114.57     33.64                14        1501            337   \n",
       "4    -114.57     33.57                20        1454            326   \n",
       "\n",
       "   population  households  medianIncome  medianHouseValue  \n",
       "0        1015         472        1.4936             66900  \n",
       "1        1129         463        1.8200             80100  \n",
       "2         333         117        1.6509             85700  \n",
       "3         515         226        3.1917             73400  \n",
       "4         624         262        1.9250             65500  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset \n",
    "\n",
    "housingdata=pd.read_csv('Datasets/california_housing.csv')\n",
    "\n",
    "# Check the first few rows of the dataset\n",
    "housingdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846eadfc",
   "metadata": {},
   "source": [
    "### Step 2: Select Features and Target\n",
    "We will separate the features (X) and the target (y), and then split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "699f94c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features (X) and target (y)\n",
    "X = housingdata.drop(columns=['median_house_value'])\n",
    "y = housingdata['median_house_value']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the feature data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d58911d",
   "metadata": {},
   "source": [
    "### Step 3: Train Base Models (Random Forest & Gradient Boosting)\n",
    "We'll now apply **Random Forest Regressor** and **Gradient Boosting Regressor** individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79c0a781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the base regressors\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "gb_regressor = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the base models\n",
    "rf_regressor.fit(X_train_scaled, y_train)\n",
    "gb_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict using the base models\n",
    "y_pred_rf = rf_regressor.predict(X_test_scaled)\n",
    "y_pred_gb = gb_regressor.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the base models using Mean Squared Error\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
    "\n",
    "print(f'Random Forest MSE: {mse_rf:.4f}')\n",
    "print(f'Gradient Boosting MSE: {mse_gb:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ce651a",
   "metadata": {},
   "source": [
    "### Step 4: Combine Models Using Voting Regressor\n",
    "Now we combine the predictions of the **Random Forest** and **Gradient Boosting** regressors using a **Voting Regressor**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc9b874d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the models using a Voting Regressor\n",
    "ensemble_model = VotingRegressor(estimators=[('rf', rf_regressor), ('gb', gb_regressor)])\n",
    "\n",
    "# Train the ensemble model\n",
    "ensemble_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions using the ensemble model\n",
    "y_pred_ensemble = ensemble_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the ensemble model using Mean Squared Error\n",
    "mse_ensemble = mean_squared_error(y_test, y_pred_ensemble)\n",
    "\n",
    "print(f'Ensemble Model (Voting Regressor) MSE: {mse_ensemble:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956de245",
   "metadata": {},
   "source": [
    "### Step 5: Compare the Results\n",
    "Let's compare the **Mean Squared Error (MSE)** values of the individual models and the ensemble model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddf495ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the MSE of individual models and the ensemble model\n",
    "print('\\nModel Performance Comparison:')\n",
    "print(f'Random Forest MSE: {mse_rf:.4f}')\n",
    "print(f'Gradient Boosting MSE: {mse_gb:.4f}')\n",
    "print(f'Ensemble (Voting) Model MSE: {mse_ensemble:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e843d43",
   "metadata": {},
   "source": [
    "### Step 6: Visualize the Results\n",
    "Let's visualize the predicted vs actual values for the ensemble model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82765c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the predicted vs actual values for the ensemble model\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(y_test, y_pred_ensemble, color='blue', label='Ensemble Model')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Ensemble Model: Predicted vs Actual')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430ae7fd",
   "metadata": {},
   "source": [
    "### Step 7: Alternative Ensemble Method - Stacking Regressor\n",
    "We can also try a **Stacking Regressor** which combines the base models using another model (e.g., Linear Regression) to make final predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80027496",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create the base models for stacking\n",
    "estimators = [\n",
    "    ('rf', rf_regressor),\n",
    "    ('gb', gb_regressor)\n",
    "]\n",
    "\n",
    "# Create the stacking regressor using a linear regression as the final estimator\n",
    "stacking_model = StackingRegressor(estimators=estimators, final_estimator=LinearRegression())\n",
    "\n",
    "# Train the stacking model\n",
    "stacking_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions with the stacking model\n",
    "y_pred_stacking = stacking_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the stacking model\n",
    "mse_stacking = mean_squared_error(y_test, y_pred_stacking)\n",
    "print(f'Stacking Regressor MSE: {mse_stacking:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
